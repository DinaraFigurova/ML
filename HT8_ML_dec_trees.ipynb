{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание по теме \"Деревья решений\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения домашнего задания необходимо взять boston house-prices datase (sklearn.datasets.load_boston) и сделать тоже самое для задачи регрессии (попробовать разные алгоритмы, поподбирать параметры, вывести итоговое качество)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализация:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Anaconda\n",
      "\n",
      "  added / updated specs:\n",
      "    - jupyterthemes\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.9.2                |   py38h9f7ea03_0         2.9 MB\n",
      "    jupyterthemes-0.20.0       |             py_1         6.1 MB  conda-forge\n",
      "    lesscpy-0.13.0             |             py_1          35 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  jupyterthemes      conda-forge/noarch::jupyterthemes-0.20.0-py_1\n",
      "  lesscpy            conda-forge/noarch::lesscpy-0.13.0-py_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                        4.8.3-py38_0 --> 4.9.2-py38h9f7ea03_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "jupyterthemes-0.20.0 | 6.1 MB    |            |   0% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    |            |   0% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | 2          |   2% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | 6          |   6% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #1         |  11% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #8         |  19% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ##6        |  26% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ###2       |  33% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ###8       |  39% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ####5      |  45% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #####1     |  52% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #####8     |  59% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ######6    |  66% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #######3   |  73% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #######9   |  80% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ########6  |  86% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #########3 |  93% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | #########9 |  99% \n",
      "jupyterthemes-0.20.0 | 6.1 MB    | ########## | 100% \n",
      "\n",
      "lesscpy-0.13.0       | 35 KB     |            |   0% \n",
      "lesscpy-0.13.0       | 35 KB     | ####5      |  46% \n",
      "lesscpy-0.13.0       | 35 KB     | ########## | 100% \n",
      "\n",
      "conda-4.9.2          | 2.9 MB    |            |   0% \n",
      "conda-4.9.2          | 2.9 MB    |            |   1% \n",
      "conda-4.9.2          | 2.9 MB    | 6          |   7% \n",
      "conda-4.9.2          | 2.9 MB    | #2         |  13% \n",
      "conda-4.9.2          | 2.9 MB    | ##         |  20% \n",
      "conda-4.9.2          | 2.9 MB    | ##9        |  29% \n",
      "conda-4.9.2          | 2.9 MB    | ###7       |  37% \n",
      "conda-4.9.2          | 2.9 MB    | ####5      |  45% \n",
      "conda-4.9.2          | 2.9 MB    | #####2     |  52% \n",
      "conda-4.9.2          | 2.9 MB    | ######1    |  61% \n",
      "conda-4.9.2          | 2.9 MB    | ########2  |  83% \n",
      "conda-4.9.2          | 2.9 MB    | #########3 |  93% \n",
      "conda-4.9.2          | 2.9 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso, Ridge, HuberRegressor, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston['data']\n",
    "y = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим выборку на тренировочную и тестовую:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применим разные варианты регрессий:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Лассо регрессия*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём некоторые оптимальные гиперпараметры для данной регрессии: 'alpha' и 'selection' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4000 candidates, totalling 40000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4208 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 17200 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 35312 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 40000 out of 40000 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.00925754e-03, 1.01860077e-03, ...,\n",
       "       9.81738896e+04, 9.90827380e+04, 1.00000000e+05]),\n",
       "                         'selection': ['cyclic', 'random']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_params = {\n",
    "    'alpha': np.logspace(-3, 5, 2000),\n",
    "    'selection' : ['cyclic', 'random']\n",
    "}\n",
    "grid_lasso = GridSearchCV(lasso_reg, lasso_params, cv=10, verbose=2, n_jobs=-1)\n",
    "grid_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем наилучшие результаты нашего исследования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры: {'alpha': 0.0027556249611976015, 'selection': 'random'} . Наилучшая оценка предсказания: 0.7124699906971095\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшие гиперпараметры:\", grid_lasso.best_params_, \". Наилучшая оценка предсказания:\", grid_lasso.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем такое же исследование для *Ридж-регрессии*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12000 candidates, totalling 120000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1616 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3198 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4896 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7086 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 9756 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 12918 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 16560 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 20694 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 25308 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 30414 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 36000 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 42078 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 48636 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 55686 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 63216 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 71238 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 79740 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 102024 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120000 out of 120000 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Ridge(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.00925754e-03, 1.01860077e-03, ...,\n",
       "       9.81738896e+04, 9.90827380e+04, 1.00000000e+05]),\n",
       "                         'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg',\n",
       "                                    'sag', 'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_params = {\n",
    "    'alpha': np.logspace(-3, 5, 2000),\n",
    "    'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "grid_ridge = GridSearchCV(ridge_reg, ridge_params, cv=10, verbose=2, n_jobs=-1)\n",
    "grid_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры: {'alpha': 0.04373412180769153, 'solver': 'cholesky'} . Наилучшая оценка предсказания: 0.712451410169829\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшие гиперпараметры:\", grid_ridge.best_params_, \". Наилучшая оценка предсказания:\", grid_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь исследуем *Регрессию Хьюберта*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_reg = HuberRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20000 candidates, totalling 200000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1244 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2376 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3836 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 5616 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7724 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10152 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12908 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 15984 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 19388 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 23112 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 27164 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 31536 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 36236 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 41256 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 46604 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 52272 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 58268 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 64584 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 71228 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 78192 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 85484 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 93096 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 101036 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 109296 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 117884 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 126792 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 136028 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 145584 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 155468 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 165672 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 176204 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 187056 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 198236 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200000 out of 200000 | elapsed: 25.9min finished\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=HuberRegressor(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.09698580e-03, 1.20337784e-03, 1.32008840e-03,\n",
       "       1.44811823e-03, 1.58856513e-03, 1.74263339e-03, 1.91164408e-03,\n",
       "       2.09704640e-03, 2.30043012e-03, 2.52353917e-03, 2.76828663e-03,\n",
       "       3.03677112e-03, 3.33129479e-03, 3.65438307e-03, 4.00880633e-03,\n",
       "       4.39760361e-03, 4.82410870e-...\n",
       "       1.65656566, 1.66666667, 1.67676768, 1.68686869, 1.6969697 ,\n",
       "       1.70707071, 1.71717172, 1.72727273, 1.73737374, 1.74747475,\n",
       "       1.75757576, 1.76767677, 1.77777778, 1.78787879, 1.7979798 ,\n",
       "       1.80808081, 1.81818182, 1.82828283, 1.83838384, 1.84848485,\n",
       "       1.85858586, 1.86868687, 1.87878788, 1.88888889, 1.8989899 ,\n",
       "       1.90909091, 1.91919192, 1.92929293, 1.93939394, 1.94949495,\n",
       "       1.95959596, 1.96969697, 1.97979798, 1.98989899, 2.        ])},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_params = {\n",
    "    'alpha': np.logspace(-3, 5, 200),\n",
    "    'epsilon': np.linspace(1, 2, 100)\n",
    "}\n",
    "grid_huber = GridSearchCV(huber_reg, huber_params, cv=10, verbose=2, n_jobs=-1)\n",
    "grid_huber.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры: {'alpha': 0.6517339604882427, 'epsilon': 1.3838383838383839} . Наилучшая оценка предсказания: 0.691724541028457\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшие гиперпараметры:\", grid_huber.best_params_, \". Наилучшая оценка предсказания:\", grid_huber.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдём к регрессии *ElasticNet*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "elast_reg = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10000 candidates, totalling 100000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2192 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 15184 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 33296 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 56656 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 85136 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100000 out of 100000 | elapsed:   40.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=ElasticNet(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.09698580e-03, 1.20337784e-03, 1.32008840e-03,\n",
       "       1.44811823e-03, 1.58856513e-03, 1.74263339e-03, 1.91164408e-03,\n",
       "       2.09704640e-03, 2.30043012e-03, 2.52353917e-03, 2.76828663e-03,\n",
       "       3.03677112e-03, 3.33129479e-03, 3.65438307e-03, 4.00880633e-03,\n",
       "       4.39760361e-03, 4.82410870e-03, 5...\n",
       "       0.30612245, 0.32653061, 0.34693878, 0.36734694, 0.3877551 ,\n",
       "       0.40816327, 0.42857143, 0.44897959, 0.46938776, 0.48979592,\n",
       "       0.51020408, 0.53061224, 0.55102041, 0.57142857, 0.59183673,\n",
       "       0.6122449 , 0.63265306, 0.65306122, 0.67346939, 0.69387755,\n",
       "       0.71428571, 0.73469388, 0.75510204, 0.7755102 , 0.79591837,\n",
       "       0.81632653, 0.83673469, 0.85714286, 0.87755102, 0.89795918,\n",
       "       0.91836735, 0.93877551, 0.95918367, 0.97959184, 1.        ])},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elast_params = {\n",
    "    'alpha': np.logspace(-3, 5, 200),\n",
    "    'l1_ratio': np.linspace(0, 1, 50)\n",
    "}\n",
    "grid_elast = GridSearchCV(elast_reg, elast_params, cv=10, verbose=2, n_jobs=-1)\n",
    "grid_elast.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры: {'alpha': 0.0027682866303920667, 'l1_ratio': 1.0} Наилучшая оценка предсказания: 0.7124696578426108\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшие гиперпараметры:\", grid_elast.best_params_, \"Наилучшая оценка предсказания:\", grid_elast.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посмотрим, что получается с регрессией *Деревья решений*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2133 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae', 'friedman_mse'],\n",
       "                         'max_depth': range(1, 11),\n",
       "                         'min_samples_leaf': [1, 2, 4, 8, 16],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_params = {\n",
    "    'max_depth': range(1, 11),\n",
    "    'splitter': ['best', 'random'],\n",
    "    'criterion': ['mse', 'mae', 'friedman_mse'],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16]\n",
    "}\n",
    "grid_tree = GridSearchCV(tree_reg, tree_params, cv=10, verbose=2, n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры: {'criterion': 'friedman_mse', 'max_depth': 8, 'min_samples_leaf': 2, 'splitter': 'best'} Наилучшая оценка предсказания: 0.7684230889989335\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшие гиперпараметры:\", grid_tree.best_params_, \"Наилучшая оценка предсказания:\", grid_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведем совокупную оценку качества наших моделей.**\n",
    "\n",
    "Сначала посмотрим, что у нас вышло на тренировочных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'lasso': grid_lasso,\n",
    "    'rige': grid_ridge,\n",
    "    'huber': grid_huber,\n",
    "    'elasticNet': grid_elast,\n",
    "    'tree': grid_tree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso CV R^2: 0.7124699906971095 Validation R^2: 0.7523518608250437\n",
      "rige CV R^2: 0.712451410169829 Validation R^2: 0.7523678795464146\n",
      "huber CV R^2: 0.691724541028457 Validation R^2: 0.6442575820846107\n",
      "elasticNet CV R^2: 0.7124696578426108 Validation R^2: 0.7523515593711791\n",
      "tree CV R^2: 0.7684230889989335 Validation R^2: 0.9608997774572935\n"
     ]
    }
   ],
   "source": [
    "for est in estimators:\n",
    "    m = estimators[est]\n",
    "    print(est, \"CV R^2:\", m.best_score_, \"Validation R^2:\", m.best_estimator_.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, самый лучший результат получился у регрессии \"Деревья решений\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим тестовые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso CV R^2: 0.7124699906971095 Validation R^2: 0.6660879915826171\n",
      "rige CV R^2: 0.712451410169829 Validation R^2: 0.6655065226735672\n",
      "huber CV R^2: 0.691724541028457 Validation R^2: 0.5945262046525202\n",
      "elasticNet CV R^2: 0.7124696578426108 Validation R^2: 0.6660937581446583\n",
      "tree CV R^2: 0.7684230889989335 Validation R^2: 0.7611308402878274\n"
     ]
    }
   ],
   "source": [
    "for est in estimators:\n",
    "    m = estimators[est]\n",
    "    print(est, \"CV R^2:\", m.best_score_, \"Validation R^2:\", m.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовых данных также побеждает регрессия \"Деревья решений\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
